## `パイプライン`
### 全体フロー
---
| # | タスク | プラットフォーム | 詳細 |
|:--------|:------|:----------------|:-----|
| **0.** | 環境構築 | PC / Jetson | 開発環境セットアップ（ライブラリ、ツールインストール） |
| **1.** | 画像データ準備 | PC | 異常検知用の学習・検証用画像の取得と格納 |
| **2.** | 初期学習 | PC | 異常検知モデルの学習 |
| **3.** | 再学習 | Jetson | Jetson上でのモデル再学習 |
| **4.** | TensorRTエンジン化 | Jetson | モデルをTensorRTエンジンへ変換 |
| **5.** | 推論実行 | Jetson | TensorRTエンジンによる異常検知（推論）の実行 |
---

### 0. 環境構築

- [環境構築](0_environment.md) 参照
<br>
- PC側
  `ubuntu22.04 (WSL2)`
  `CUDA12.2 ～ CUDA12.8` まで動作確認
<br>
- Jetson側
  `JetPack 6.2 / TensorRT 10.3  / CUDA12.6`
  - `Kitware APT` で `cmake` をアップグレード
  - `FAISS v1.10.0` インストール

---

### 1. 画像データの準備(PC)

1. 学習・検証用画像のダウンロード (VisAの場合)
    - `data/shellscript/download_VisA.sh` を実行することで、VisA データセットをダウンロード可能です
    - 格納先ディレクトリ `data/download/`
    - AWS配布元: https://amazon-visual-anomaly.s3.amazonaws.com/VisA_20220922.tar
    - VisA データセット
      - 異常検知向け産業用データセット(12カテゴリ)
      - 正常・異常ラベルあり(ディレクトリとして)
      - ライセンス CC BY 4.0 (Creative Commons Attribution 4.0 International)<br><br>
2. `train/` `test/` ディレクトリへの格納
    - `data/shellscript/move_VisA.sh <category_name>` を実行することで、ダウンロードした画像データを学習用に配置します。
    - 格納先ディレクトリ
        - 学習用 `data/train/`　※正常のみ
        - 検証用 `data/test/` 　 ※正常・異常あり

---
### 2. 異常検知モデルの初期学習(PC)

##### 2-1. コンテナ起動・JupyterLab へのアクセス
> - `1.` Windows Powershell を起動して、Ubuntu on WSL2 を立ち上げます
>     ```
>     wsl -d Ubuntu (または、Ubuntu-22.04)
>     ```
> - `2.` docker-compose.yml が存在するディレクトリに移動して、dockerコンテナを起動します
>     ```
>    $ cd <任意のパス>/1_train_jupyterlab_docker/
>    $ docker compose up -d
>    ```
> - `3.` docker コンテナが正常に起動していることを確認します
>    ```
>    $ docker ps
>    ```
> - `4.` Webブラウザを起動して、以下のURLからJupyterLabへアクセスします
>    ```
>    http://localhost:8888
>    ```

##### 2-2.  学習スクリプトの実行

- `script/` ディレクトリ内に、異常検知モデル別のスクリプトファイルが存在します
- 対象モデルのファイルを開き `0.` ～ `4.` のセルを順番に実行します。(`2.` と `4.` はスキップ可能)

>
>  - `0.` **CUDA Version 確認**
>       - docker コンテナは、CUDA version: 12.2 (Torch 2.6.0) で構築しています
>       - `12.2 ～ 12.8` まで互換性を確認しております
>       - `cuda available:`**`True`** であれば実行可能です<br><br>
>
>  - `1.` **初期設定**
>       - ユーザー設定項目として以下を変更可能です（★の項目）。
>         - `IMAGE_SIZE`　　　　　　： 画像サイズ
>         - `IMAGE_THRESHOLD`　　　　：異常検知閾値
>         - `CATEGORY`　　　　　　　：検出対象のカテゴリ
>       - 説明
>         - 画像サイズ: 入力画像のサイズではなく内部処理でリサイズする大きさ
>         - 異常検知閾値: 異常検知モデルが出力するスコアに対して正常/異常を弁別する閾値
>            ※ 検出性能テストで閾値を自動に決める（発見する）ことも可能です
>         - 検出対象のカテゴリ: 画像カテゴリのディレクトリ名を指定
>          ※ 異常検知モデルは基本的に１つの画像カテゴリ毎に学習することが可能です<br><br>
>
>  - `2.` **ハイパーパラメータ探索**
>       - 正常・異常画像両方を使った事前学習＆検証を行うことで、ターゲットカテゴリの画像に適した
>ハイパーパラメータを自動で探索することができます(Optunaを利用)
>       - 探索する範囲（サーチスペース）を設定することができます（★の項目）
>         - 各モデル別のハイパーパラメータについては [異常検知モデル一覧](2_models.md#modellist) を参照
>       - 探索条件の中で最適なハイパーパラメータは保存され、学習時に利用されます
>       - 異常検知モデルはすべて教師なし学習ですが、ハイパーパラメータ探索は異常ラベルを必要とする教師ありプロセスと言えます
>       - 完全に異常画像を使わない学習を行う場合は、ここはスキップして「3. 学習」へ進んでください
>         ※その場合、手動でハイパーパラメータの設定が必要となります<br><br>
>
>  - `3.` **学習**
>       - 「`2.` ハイパーパラメータ探索」を行わなかった場合は、ハイパーパラメータを設定します
>       - 正常画像のみを利用して学習を行います
>       - 学習後は、以下のファイルが `models/<CATEGORY>/<YYYYMMDD_HHMMSS>` ディレクトリへ保存されます。
>         - ☆`pytorch/model.pth`　　： 最終重みファイル
>         - ☆`pytorch/meta.json`　　： 学習に関するメタデータ([学習メタファイル](2_models.md#meta)を参照)
>         - `checkpoint/best.ckpt`　 ： 学習チェックポイントファイル(PCで再学習や学習分析に利用)
>       
>       - 追加保存ファイル(TensorRT化できないもの)
>         - ☆`memory_bank.npz`　　： PatchCoreの場合のみ
>         - ☆`stats.npz`　　　　　： PaDiMの場合のみ
>       - ☆がついたファイルがJetsonへ移行する対象になります
>       - `<YYYYMMDD_HHMMSS>` は、「`1.` 初期設定」を実行したシステム日時となります<br><br>
>
>  - `4.` **検出性能テスト**
>       - 学習済モデルを使い、正常・異常画像で異常検出を試行することができます
>       - テスト実行後は、以下のファイルが`models/` ディレクトリへ保存されます。
>         - `test_result/predictions.csv`　　： 画像毎の異常スコアと閾値を用いた判断結果
>         - `test_result/images/normal`　 　 ： 正常画像のアノマリーマップと異常検知マスク(参考)
>         - `test_result/images/anomaly`　　： 異常画像のアノマリーマップと異常検知マスク(参考)
>       - 最後に全体の平均精度指標（AUROC，Best F1）を算出します
>       - このテストにより、正常異常データの分布から自動的に適した閾値を求めます
>         - 求められた自動閾値は、`meta.json` の `image_threshold_auto` へ更新されます
---
#### 3. モデルの再学習(Jetson)
- Jetson 上での「3. モデルの再学習」と 「4. TensorRTエンジン化」は、dockerコンテナを起動して実行します。
- PC側で作成した学習済モデル他（上記の☆ファイル）を、Jetson 側の `models/` ディレクトリにコピー(移動)します。
  詳細は、[モデル格納ディレクトリ(Jetson)](3_structure.md#models-jetson) 参照
- ※ Jetson 上の再学習は必須ではありません。

> - **docker コンテナの構築と起動**
> ```
> $ cd 2_jetson_docker
> $ docker compose up -d --build
> ```
> - **モデル再学習**
> ```
> $ docker compose exec jetson_batch bash
> ```
> `(以下 docker コンテナ内)`
> ```
> # `python3` retrain.py + コマンド
> ```
> 詳細は [再学習コマンド](2_models.md#comretrain) を参照

---
#### 4. TensorRTエンジン化(Jetson)
- docker コンテナ内で、以下のコマンドを実行することで、
学習済モデルをONNXエクスポートした後、最終的にTensorRTエンジンへ変換します。
> ```
> # `python3` convertrt.py + コマンド
> ```
> 詳細は [TensorRT化コマンド](2_models.md#comtensorrt) を参照

---
#### 5. 推論実行(Jetson)

- TensorRTエンジンによって推論の実行を行います。
- dockerコンテナではなく、ホストOS上で直接実行します。

> ```
> $ cd 3_jetson_infer
> $ ./<binary_name> + コマンド
> ```
> 詳細は [推論コマンド](2_models.md#cominfer) を参照

- **注意**
  - Jetson上(TensorRT)で実行される推論は、PC上での推論とは異なり、正規化されない異常スコアが求められます。
  - そのため、閾値も正規化されない異常スコアに対して設定する必要があります。
  - また、正常・異常データの分布が既知ではない場合、閾値は手動で設定する必要があります。
---