{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7017c035-1de7-4e6c-ac3b-0d71fd54ab5e",
   "metadata": {},
   "source": [
    "# PatchCore Training\n",
    "\n",
    "- PatchCoreモデルを単一カテゴリデータ(Normal)で学習します\n",
    "- 推論には 「MemoryBank」 が必要になります"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0d60a-0984-4cf7-bdc4-fd6be204e5fa",
   "metadata": {},
   "source": [
    "### 0. CUDA Version 確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc559f6-5449-4743-9576-200dd651c668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch, platform\n",
    "print(\"torch version :\", torch.__version__)\n",
    "print(\"cuda in torch :\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317c868-153a-48ce-a56f-a3a1430d7e3c",
   "metadata": {},
   "source": [
    "## 1. 初期設定\n",
    "\n",
    "- 処理する画像サイズ 「IMAGE_SIZE」 と、検出対象とする画像カテゴリ 「CATEGORY」を指定してください\n",
    "- 作成された「RUN_DIR」に、学習済モデルが作成されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b25992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import yaml\n",
    "import optuna\n",
    "import torch\n",
    "\n",
    "from anomalib.data import Folder\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib.engine import Engine\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# -------- ユーザ設定項目 --------\n",
    "IMAGE_SIZE  = 256                              # 画像サイズ(★変更対象)\n",
    "IMAGE_THRESHOLD  = 0.5                         # 異常検出閾値(★変更対象)\n",
    "CATEGORY    = \"VisA_pipe_fryum\"                # 検出対象のカテゴリ(★変更対象)\n",
    "DATA_ROOT   = Path(\"/workspace/data\")          # データフォルダ(tarin/test)\n",
    "# -------------------------------\n",
    "\n",
    "JST = timezone(timedelta(hours=9))\n",
    "timestamp = datetime.now(JST).strftime('%Y%m%d_%H%M%S')  # 実行時のシステム日時\n",
    "OUTPUT_DIR  = Path(\"/workspace/models\") / \"PatchCore\" / CATEGORY  # 学習済モデルの出力先\n",
    "RUN_DIR   = OUTPUT_DIR / timestamp\n",
    "(RUN_DIR / 'checkpoint').mkdir(parents=True, exist_ok=True)\n",
    "(RUN_DIR / 'pytorch').mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR = RUN_DIR / \"temp\"\n",
    "PARAM_DIR = RUN_DIR / \"param\"\n",
    "LOG_DIR = RUN_DIR / \"logs\"\n",
    "\n",
    "print('RUN DIR:', RUN_DIR)\n",
    "\n",
    "# -------- DataModule定義 --------\n",
    "def build_datamodule() -> Folder:\n",
    "    return Folder(\n",
    "        name=CATEGORY,\n",
    "        root=DATA_ROOT,\n",
    "        normal_dir=f\"train/{CATEGORY}\",             # 学習用正常データ\n",
    "        abnormal_dir=f\"test/{CATEGORY}/anomaly\",    # テスト(評価)用異常データ (学習では使われない/Optuna探索では使われる)\n",
    "        normal_test_dir=f\"test/{CATEGORY}/normal\",  # テスト(評価)用正常データ\n",
    "        train_batch_size=16,         # default=32\n",
    "        eval_batch_size=16,          # default=32\n",
    "        extensions=(\n",
    "            \".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\",\n",
    "            \".JPG\", \".JPEG\", \".PNG\", \".BMP\", \".TIF\", \".TIFF\", \".WEBP\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd2fc0",
   "metadata": {},
   "source": [
    "## 2. ハイパーパラメータ探索 (Optuna)\n",
    "\n",
    "- ここではハイパーパラメータの自動探索を行います\n",
    "- PatchCore は、教師なし学習ですが、Optuna 探索は検証用に異常ラベルを必要とする教師ありプロセスと言えます\n",
    "- 探索を行わずに手動でハイパーパラメータを調整する場合は、ここをスキップして「3. 学習」へ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78607bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna, torch, yaml, types\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib.engine import Engine\n",
    "\n",
    "# -------- GPU利用可否 --------\n",
    "GPU_OK = torch.cuda.is_available()\n",
    "\n",
    "# -------- サーチスペース(★変更対象) --------\n",
    "N_TRIALS   = 3                        # 試行回数\n",
    "BACKBONES  = [\"resnet18\",\"resnet34\"]  # バックボーンCNN(複数可)\n",
    "LAYER_OPTS = [\n",
    "    (\"layer2\",),\n",
    "    #(\"layer2\", \"layer3\"),\n",
    "    #(\"layer1\", \"layer2\", \"layer3\"),\n",
    "]\n",
    "CORESET_RANGE = {\"low\": 0.05, \"high\": 0.10, \"step\": 0.05}\n",
    "\n",
    "# -------- Objective --------\n",
    "def objective(trial: optuna.Trial):\n",
    "\n",
    "    backbone = trial.suggest_categorical(\"backbone\", BACKBONES)\n",
    "    ratio    = trial.suggest_float(\"coreset_ratio\", **CORESET_RANGE)\n",
    "\n",
    "    # layers は Tuple → Index にして渡す\n",
    "    idx = trial.suggest_categorical(\"layers_idx\", list(range(len(LAYER_OPTS))))\n",
    "    layers = LAYER_OPTS[idx]\n",
    "    \n",
    "    # Data & Model\n",
    "    dm  = build_datamodule()\n",
    "    pre = Patchcore.configure_pre_processor(image_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    model = Patchcore(\n",
    "        backbone=backbone,\n",
    "        layers=layers,\n",
    "        coreset_sampling_ratio=ratio,\n",
    "        pre_processor=pre,\n",
    "    )\n",
    "    \n",
    "    # Engine (GPU→CPU フォールバック)\n",
    "    used_gpu = None\n",
    "    for use_gpu in (GPU_OK, False):\n",
    "        try:\n",
    "            engine = Engine(\n",
    "                logger=False,\n",
    "                default_root_dir=TEMP_DIR / \"optuna\",\n",
    "                accelerator=\"gpu\" if use_gpu else \"cpu\",\n",
    "                max_epochs=1,               # Optuna は 1 epoch 評価\n",
    "                enable_progress_bar=False,\n",
    "            )\n",
    "            engine.fit(model=model, datamodule=dm)\n",
    "            used_gpu = use_gpu\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            if \"cudaGetDeviceCount\" in str(e):\n",
    "                print(\"⚠️ CUDA 初期化エラー → CPU で再試行\")\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "    trial.set_user_attr(\"used_gpu\", used_gpu)\n",
    "    if not used_gpu:\n",
    "        print(f\"Trial {trial.number}: CPU で実行 (GPU fallback)\")\n",
    "\n",
    "    # AUROC が無ければ 0.0\n",
    "    return engine.trainer.callback_metrics.get(\"image_AUROC\", torch.tensor(0.0)).item()\n",
    "\n",
    "# -------- 探索実行 --------\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"BEST :\", study.best_params)\n",
    "print(\"AUROC:\", study.best_value)\n",
    "\n",
    "# -------- 結果保存 --------\n",
    "PARAM_DIR.mkdir(exist_ok=True)\n",
    "search_space = dict(\n",
    "    backbone      = BACKBONES,\n",
    "    layers        = LAYER_OPTS,\n",
    "    coreset_ratio = CORESET_RANGE,\n",
    ")\n",
    "yaml.safe_dump(search_space, open(PARAM_DIR / \"search_space.yaml\", \"w\"))\n",
    "best = study.best_params.copy()\n",
    "best[\"layers\"] = LAYER_OPTS[best.pop(\"layers_idx\")]  # Tupleに戻して保存\n",
    "yaml.safe_dump(best, open(PARAM_DIR / \"best_params.yaml\", \"w\"))\n",
    "study.trials_dataframe().to_csv(PARAM_DIR / \"trials.csv\", index=False)\n",
    "\n",
    "# ---------- TEMP_DIR のクリーンアップ ----------\n",
    "# Debugする場合は、コメントアウトしてください\n",
    "import shutil, gc\n",
    "if TEMP_DIR.exists():\n",
    "    # Windows でハンドルが残ると削除に失敗することがあるので、念のため GC\n",
    "    gc.collect()\n",
    "    shutil.rmtree(TEMP_DIR, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73415335",
   "metadata": {},
   "source": [
    "## 3. 学習\n",
    "\n",
    "- 「2. ハイパーパラメータ探索(Optuna)」 を行った場合は、保存されたベストパラメータで学習します\n",
    "- 自動探索を行わない行場合は、ハイパーパラメータ 「MANUAL_PARAMS」を手動で調整してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1891f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np, torch, yaml, types\n",
    "from anomalib.engine import Engine\n",
    "from anomalib.models import Patchcore\n",
    "import logging\n",
    "\n",
    "# -------- GPU/利用可否 --------\n",
    "GPU_OK = torch.cuda.is_available()\n",
    "\n",
    "# -------- 学習設定 --------\n",
    "MAX_EPOCHS = 1   # 1回のみ実施(メモリバンクcoreset作成) ※固定\n",
    "\n",
    "# -------- ★手動パラメータ（best_params.yaml が無い時に使用） --------\n",
    "MANUAL_PARAMS = dict(\n",
    "    backbone       = \"resnet18\",\n",
    "    #layers         = (\"layer2\",\"layer3\",\"layer1\",),\n",
    "    layers         = (\"layer2\",),\n",
    "    coreset_ratio  = 0.10,\n",
    ")\n",
    "\n",
    "# -------- best_params.yaml 読み込み --------\n",
    "best_params_path = PARAM_DIR / \"best_params.yaml\"\n",
    "\n",
    "if best_params_path.exists():\n",
    "    cfg = yaml.safe_load(open(best_params_path))\n",
    "    print(\"▶ Using best_params.yaml:\", cfg)\n",
    "else:\n",
    "    cfg = MANUAL_PARAMS.copy()\n",
    "    print(\"▶ Using manual params:\", cfg)\n",
    "\n",
    "# -------- layers をタプル化 --------\n",
    "raw_layers = cfg[\"layers\"]\n",
    "if isinstance(raw_layers, (list, tuple)):\n",
    "    layers_tuple = tuple(raw_layers)\n",
    "else:\n",
    "    layers_tuple = eval(raw_layers)\n",
    "\n",
    "# -------- Model & DataModule --------\n",
    "pre   = Patchcore.configure_pre_processor(image_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "model = Patchcore(\n",
    "    backbone               = cfg[\"backbone\"],\n",
    "    layers                 = layers_tuple,\n",
    "    coreset_sampling_ratio = cfg[\"coreset_ratio\"],\n",
    "    pre_processor          = pre,\n",
    ")\n",
    "dm = build_datamodule()\n",
    "\n",
    "# -------- Lightning学習 (GPU/CPUフォールバック) --------\n",
    "tb_logger = TensorBoardLogger(save_dir=RUN_DIR / \"logs\", name=\"final\")\n",
    "\n",
    "used_gpu  = None\n",
    "for use_gpu in (GPU_OK, False):\n",
    "    try:\n",
    "        engine = Engine(\n",
    "            default_root_dir=TEMP_DIR / \"train\",\n",
    "            accelerator        = \"gpu\" if use_gpu else \"cpu\",\n",
    "            max_epochs         = MAX_EPOCHS,\n",
    "            log_every_n_steps  = 1,\n",
    "            enable_progress_bar= False,\n",
    "            logger             = tb_logger,\n",
    "        )\n",
    "        engine.fit(model=model, datamodule=dm)\n",
    "        used_gpu = use_gpu\n",
    "        break\n",
    "    except RuntimeError as e:\n",
    "        if \"cudaGetDeviceCount\" in str(e):\n",
    "            print(\"⚠️ CUDA 初期化エラー → CPU でリトライ\")\n",
    "            continue\n",
    "        raise\n",
    "\n",
    "if not used_gpu:\n",
    "    print(\"⚠️ GPU 使用不可 → CPU で学習完了\")\n",
    "\n",
    "# -------- MemoryBank 保存 --------\n",
    "mb_dir = RUN_DIR / \"pytorch\"; mb_dir.mkdir(parents=True, exist_ok=True)\n",
    "embeddings = engine.model.model.memory_bank.cpu().numpy()\n",
    "np.savez_compressed(mb_dir / \"memory_bank.npz\", embeddings=embeddings)\n",
    "print(\"✓ MemoryBank:\", mb_dir / \"memory_bank.npz\")\n",
    "\n",
    "# -------- Checkpoint 保存 --------\n",
    "ckpt_path = RUN_DIR / \"checkpoint\" / \"best.ckpt\"\n",
    "engine.trainer.save_checkpoint(ckpt_path)\n",
    "print(\"✓ Checkpoint :\", ckpt_path)\n",
    "\n",
    "# -------- 推論用モデル .pth 保存 -------- \n",
    "state_path = RUN_DIR / \"pytorch\" / \"model.pth\"\n",
    "torch.save(model.state_dict(), state_path)\n",
    "print(\"✓ Weights :\", state_path)\n",
    "\n",
    "# ======== 学習データのみ推論して image_min, image_max を取得 ========\n",
    "# 正規化のために推論処理へ連携する (別の方法 Z-Score(μ, σ)正規化もあり)\n",
    "print(f\"Computing image_min and image_max ...\")\n",
    "\n",
    "# Post-Processor の正規化だけオフにする\n",
    "model.post_processor.enable_normalization = False\n",
    "\n",
    "# DataModule を train のみでセットアップ\n",
    "dm.setup(\"fit\")                         # train フェーズ相当\n",
    "predict_loader = dm.train_dataloader()  # train データを予測\n",
    "\n",
    "# Engine.predict で生マップを取得\n",
    "scores = []\n",
    "logging.getLogger(\"anomalib.visualization.image.item_visualizer\").setLevel(logging.ERROR)\n",
    "for batch in engine.predict(model=model, datamodule=dm, return_predictions=True):\n",
    "    # batch は list of ImagePrediction\n",
    "    for item in batch:\n",
    "        # 生の anomaly_map を最大値で画像ごとの raw スコアに\n",
    "        raw = float(item.anomaly_map.max().cpu())\n",
    "        scores.append(raw)\n",
    "\n",
    "# 正規化機構を元に戻す\n",
    "model.post_processor.enable_normalization = True\n",
    "\n",
    "# image_min と image_max を計算\n",
    "image_min = float(np.min(scores))\n",
    "image_max = float(np.max(scores))\n",
    "print(f\"Computed image_min: {image_min}, image_max: {image_max}\")\n",
    "# ==================================================================\n",
    "\n",
    "# ------- .pth に含まれないメタ情報を出力(json) -------\n",
    "import json\n",
    "meta_path = Path(RUN_DIR) / \"pytorch\" / \"meta.json\"\n",
    "meta = {\n",
    "    \"backbone\"            : cfg[\"backbone\"],\n",
    "    \"layers\"              : list(layers_tuple),\n",
    "    \"coreset_ratio\"       : cfg[\"coreset_ratio\"],\n",
    "    \"image_size\"          : IMAGE_SIZE,\n",
    "    \"weights_pth\"         : state_path.name,\n",
    "    \"memory_bank\"         : \"memory_bank.npz\",\n",
    "    \"image_threshold\"     : IMAGE_THRESHOLD,  # 手動設定\n",
    "    \"image_threshold_auto\": IMAGE_THRESHOLD,  # Test後に上書き用(任意)\n",
    "    \"image_min\"           : image_min,\n",
    "    \"image_max\"           : image_max,\n",
    "}\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✓ Meta JSON :\", meta_path)\n",
    "\n",
    "# ---------- TEMP_DIR のクリーンアップ ----------\n",
    "# Debugする場合は、コメントアウトしてください\n",
    "import shutil, gc\n",
    "if TEMP_DIR.exists():\n",
    "    # Windows でハンドルが残ると削除に失敗することがあるので、念のため GC\n",
    "    gc.collect()\n",
    "    shutil.rmtree(TEMP_DIR, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebafd68-af71-4cf4-bc00-d564fb742559",
   "metadata": {},
   "source": [
    "## 4. 検出性能テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fffb21-99c0-4c1b-90ad-45a649fff250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib.engine import Engine\n",
    "import torch, pandas as pd, shutil, json, logging\n",
    "\n",
    "# ---------- パス・デバイス ----------\n",
    "state_path  = Path(RUN_DIR / \"pytorch\" / \"model.pth\")\n",
    "result_root = RUN_DIR / \"test_result\"\n",
    "device      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------- meta.json 読込 --------\n",
    "meta_path = Path(RUN_DIR / \"pytorch\" / \"meta.json\")\n",
    "with open(meta_path, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "threshold = float(meta.get(\"image_threshold\", 0.5))\n",
    "\n",
    "# ---------- モデル ----------\n",
    "model = Patchcore(\n",
    "    backbone=cfg[\"backbone\"],\n",
    "    layers=layers_tuple,\n",
    "    coreset_sampling_ratio=cfg[\"coreset_ratio\"],\n",
    "    pre_processor=pre,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(state_path, map_location=device), strict=True)\n",
    "model.eval()\n",
    "\n",
    "# ---------- DataModule ----------\n",
    "dm = build_datamodule()\n",
    "dm.setup(\"test\")\n",
    "\n",
    "# suppress visualizer logs\n",
    "logging.getLogger(\"anomalib.visualization.image.item_visualizer\").setLevel(logging.ERROR)\n",
    "\n",
    "# ---------- テスト ----------\n",
    "engine = Engine(\n",
    "    accelerator=\"gpu\" if device == \"cuda\" else \"cpu\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=False,\n",
    "    logger=False,\n",
    ")\n",
    "engine.test(model=model, datamodule=dm)\n",
    "\n",
    "metrics = engine.trainer.callback_metrics.copy()\n",
    "auroc   = float(metrics.get(\"image_AUROC\", 0))\n",
    "f1      = float(metrics.get(\"image_F1Score\", 0))\n",
    "\n",
    "# testで自動決定される image_threshold \n",
    "threshold = float(getattr(model.post_processor, \"image_threshold\", IMAGE_THRESHOLD))\n",
    "\n",
    "# ---------- 1枚ずつチェック ----------\n",
    "def get_gt(item):\n",
    "    for key in (\"label\", \"labels\", \"is_anomaly\", \"targets\"):\n",
    "        if hasattr(item, key):\n",
    "            return int(getattr(item, key))\n",
    "    parent = Path(item.image_path).parent.name.lower()\n",
    "    return 1 if parent == \"anomaly\" else 0\n",
    "\n",
    "records = []\n",
    "print(f\"\\nThreshold (normalized): {threshold:.4f}\\n\")\n",
    "for batch in engine.predict(model=model, datamodule=dm):\n",
    "    for item in batch:\n",
    "        file      = Path(item.image_path).name\n",
    "        norm_score = float(item.pred_score)  # 正規化後スコア（enable_normalization=True 時と同じ）\n",
    "        # 生スコアは anomaly_map の最大値\n",
    "        raw_score = float(item.anomaly_map.max())  \n",
    "        pred_label = \"anomaly\" if int(item.pred_label) == 1 else \"normal\"\n",
    "        gt_label   = \"anomaly\" if get_gt(item) else \"normal\"\n",
    "        print(f\"{file:40s} | raw={raw_score:7.4f} | norm={norm_score:7.4f} | pred={pred_label:7s} | gt={gt_label}\")\n",
    "        records.append({\n",
    "            \"file\": file,\n",
    "            \"raw_score\": raw_score,\n",
    "            \"norm_score\": norm_score,\n",
    "            \"pred\": pred_label,\n",
    "            \"label\": gt_label\n",
    "        })\n",
    "        \n",
    "# ---------- CSV 保存 ----------\n",
    "result_root.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = result_root / \"predictions.csv\"\n",
    "pd.DataFrame(records).to_csv(csv_path, index=False)\n",
    "print(f\"\\n✓ predictions.csv saved to {csv_path}\\n\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# ---------- meta.json 更新 (image_threshold_auto) ----------\n",
    "meta_path = Path(RUN_DIR) / \"pytorch\" / \"meta.json\"\n",
    "with open(meta_path, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "meta[\"image_threshold_auto\"] = float(threshold)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ threshold_auto updated to {meta_path}\")\n",
    "\n",
    "# ---------- 指標 ----------\n",
    "print(\"\\n==========  EVALUATION  ==========\")\n",
    "print(f\"Images tested : {len(dm.test_data)}\")\n",
    "print(f\"AUROC         : {auroc:7.4f}\")\n",
    "print(f\"Best F1       : {f1:7.4f}\")\n",
    "print(\"===================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81dfd17-c328-441c-81a8-1ee7479c945b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
